当引擎将国内板块url对应的请求提交给下载器后，下载器进行网页数据的下载，然后将下载到的页面数据，封装到response中，提交给引擎，引擎将response在转交给Spiders

# 学习强国网

链接:https://www.xuexi.cn/f997e76a890b0e5a053c57b19f468436/018d244441062d8916dd472a4c6a0a0b.html

需求:获取新闻内容

参考教程:https://www.cnblogs.com/presleyren/p/10595740.html

分析：

　　1.首先通过分析页面会发现该页面中的新闻数据都是动态加载出来的，并且通过抓包工具抓取数据可以发现动态数据也不是ajax请求获取的动态数据（因为没有捕获到ajax请求的数据包），那么只剩下一种可能，该动态数据是js动态生成的。

　　2.通过抓包工具查找到底数据是由哪个js请求产生的动态数据：打开抓包工具，然后对首页url（第一行需求中的url）发起请求，捕获所有的请求数据包。

# selenium避开检测

参考教程:https://www.cnblogs.com/presleyren/p/10771000.html

# Http协议

https://www.cnblogs.com/presleyren/p/10698722.html

6.HTTP之Request：

　　　　*客户端发送一个HTTP请求到服务器的请求消息包括以下组成部分：*

*[![img](https://img2018.cnblogs.com/blog/1489694/201809/1489694-20180914105821455-775348403.png)](https://img2018.cnblogs.com/blog/1489694/201809/1489694-20180914105821455-775348403.png)*

　　　　报文头：常被叫做请求头，请求头中存储的是该请求的一些主要说明（自我介绍）。服务器据此获取客户端的信息。

　　　　　　　　常见的请求头：

　　　　　　　　*accept:浏览器通过这个头告诉服务器，它所支持的数据类型*

　　　　　　　　*Accept-Charset: 浏览器通过这个头告诉服务器，它支持哪种字符集
　　　　　　　　Accept-Encoding：浏览器通过这个头告诉服务器，支持的压缩格式
　　　　　　　　Accept-Language：浏览器通过这个头告诉服务器，它的语言环境
　　　　　　　　Host：浏览器通过这个头告诉服务器，想访问哪台主机
　　　　　　　　If-Modified-Since: 浏览器通过这个头告诉服务器，缓存数据的时间
　　　　　　　　Referer：浏览器通过这个头告诉服务器，客户机是哪个页面来的 防盗链
　　　　　　　　Connection：浏览器通过这个头告诉服务器，请求完后是断开链接还是何持链接
　　　　　　　　X-Requested-With: XMLHttpRequest 代表通过ajax方式进行访问*

　　　　　　　　*User-Agent：请求载体的身份标识
*

　　　　报文体：常被叫做请求体，请求体中存储的是将要传输/发送给服务器的数据信息。

　　　　

　　7.HTTP之Response：

　　　　服务器回传*一个HTTP响应到客户端的响应消息包括以下组成部分：*

　　　　　　　　*[![img](https://img2018.cnblogs.com/blog/1489694/201809/1489694-20180914112109546-492688431.png)](https://img2018.cnblogs.com/blog/1489694/201809/1489694-20180914112109546-492688431.png)*

　　　　状态码：以“清晰明确”的语言告诉客户端本次请求的处理结果。

　　　　　　　　HTTP的响应状态码由5段组成： 

- - - - 　　1xx 消息，一般是告诉客户端，请求已经收到了，正在处理，别急...
      - 　　2xx 处理成功，一般表示：请求收悉、我明白你要的、请求已受理、已经处理完成等信息.
      - 　　3xx 重定向到其它地方。它让客户端再发起一个请求以完成整个处理。
      - 　　4xx 处理发生错误，责任在客户端，如客户端的请求一个不存在的资源，客户端未被授权，禁止访问等。
      - 　　5xx 处理发生错误，责任在服务端，如服务端抛出异常，路由出错，HTTP版本不支持等。

　　　　相应头：响应的详情展示

　　　　　　　　常见的相应头信息：

　　　　　　　　　　　　Location: 服务器通过这个头，来告诉浏览器跳到哪里
　　　　　　　　　　　　Server：服务器通过这个头，告诉浏览器服务器的型号
　　　　　　　　　　　　Content-Encoding：服务器通过这个头，告诉浏览器，数据的压缩格式
　　　　　　　　　　　　Content-Length: 服务器通过这个头，告诉浏览器回送数据的长度
　　　　　　　　　　　　Content-Language: 服务器通过这个头，告诉浏览器语言环境
　　　　　　　　　　　　Content-Type：服务器通过这个头，告诉浏览器回送数据的类型
　　　　　　　　　　　　Refresh：服务器通过这个头，告诉浏览器定时刷新
　　　　　　　　　　　　Content-Disposition: 服务器通过这个头，告诉浏览器以下载方式打数据
　　　　　　　　　　　　Transfer-Encoding：服务器通过这个头，告诉浏览器数据是以分块方式回送的
　　　　　　　　　　　　Expires: -1 控制浏览器不要缓存
　　　　　　　　　　　　Cache-Control: no-cache
　　　　　　　　　　　　Pragma: no-cache

　　　　响应体：根据客户端指定的请求信息，发送给客户端的指定数据

 https://www.cnblogs.com/wyq178/p/7129232.html

# scrapy-redis

https://www.cnblogs.com/presleyren/p/10595755.html

# selenium中间件

https://www.cnblogs.com/presleyren/p/10595748.html

# Python网络爬虫之Scrapy框架（CrawlSpider）

https://www.cnblogs.com/presleyren/p/10595753.html

CrawlSpider整体爬取流程：

　　　　a)爬虫文件首先根据起始url，获取该url的网页内容

　　　　b)链接提取器会根据指定提取规则将步骤a中网页内容中的链接进行提取

　　　　c)规则解析器会根据指定解析规则将链接提取器中提取到的链接中的网页内容根据指定的规则进行解析

　　　　d)将解析数据封装到item中，然后提交给管道进行持久化存储

LinkExtractor(

​								allow=r'Items/'，# 满足括号中“正则表达式”的值会被提取，如果为空，则全部匹配。

　　　　　　　　 deny=xxx, # 满足正则表达式的则不会被提取。

 

　　　　　　　　 restrict_xpaths=xxx, # 满足xpath表达式的值会被提取

　　　　　　　　 restrict_css=xxx, # 满足css表达式的值会被提取

　　　　　　　　 deny_domains=xxx, # 不会被提取的链接的domains。

)　

# UA池

https://www.cnblogs.com/presleyren/p/10595744.html

# 增量式爬虫

- 概念：通过爬虫程序监测某网站数据更新的情况，以便可以爬取到该网站更新出的新数据。

- 如何进行增量式的爬取工作：

  - 在发送请求之前判断这个URL是不是之前爬取过

  - 在解析内容后判断这部分内容是不是之前爬取过

  - 写入存储介质时判断内容是不是已经在介质中存在

    - 分析：

         不难发现，其实增量爬取的核心是**去重**， 至于去重的操作在哪个步骤起作用，只能说各有利弊。在我看来，前两种思路需要根据实际情况取一个（也可能都用）。第一种思路适合不断有新页面出现的网站，比如说小说的新章节，每天的最新新闻等等；第二种思路则适合页面内容会更新的网站。第三个思路是相当于是最后的一道防线。这样做可以最大程度上达到去重的目的。

- 去重方法

  - 将爬取过程中产生的url进行存储，存储在redis的set中。当下次进行数据爬取时，首先对即将要发起的请求对应的url在存储的url的set中做判断，如果存在则不进行请求，否则才进行请求。
  - 对爬取到的网页内容进行唯一标识的制定，然后将该唯一表示存储至redis的set中。当下次爬取到网页数据的时候，在进行持久化存储之前，首先可以先判断该数据的唯一标识在redis的set中是否存在，在决定是否进行持久化存储。

https://www.cnblogs.com/presleyren/p/10595757.html

# 关于反爬虫

https://www.jb51.net/article/197404.htm

## CDP规避webdriver被网站读取

 Google 的Chrome Devtools-Protocol（Chrome 开发工具协议）简称CDP。

我们打开 CPD 的官方文档[1]，可以看到如下的命令：
[![在这里插入图片描述](https://img-blog.csdnimg.cn/20200305224053993.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTE3MzM3NA==,size_16,color_FFFFFF,t_70)](https://img-blog.csdnimg.cn/20200305224053993.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTE3MzM3NA==,size_16,color_FFFFFF,t_70)

https://www.cnblogs.com/presleyren/p/12936553.html

```
from selenium import webdriver
options = webdriver.ChromeOptions()
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)
driver = webdriver.Chrome(options=options, executable_path='./chromedriver')
driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
  "source": """
    Object.defineProperty(navigator, 'webdriver', {
      get: () => undefined
    })
  """
})
driver.get('http://exercise.kingname.info')
```

